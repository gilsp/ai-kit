{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Kit\n",
    "\n",
    "This jupyter notebook series constitutes a miscellaneous collection of code-snippeds for generic tasks in ML/DL-projects. The purpose is to speed up and ease model development by providing content for copying / pasting / and further customization. Each section constitutes a separat jupyter notebook.\n",
    "\n",
    "#### A - BASICS\n",
    "1. **Data Preprocessing** - Imputation, Normalization\n",
    "2. **Oulier Detection** - Univariate Z-Score, Isolation Forest, Elliptic Envelope, DBSCAN\n",
    "3. **Dimensionality Reduction** - PCA, tSNE\n",
    "\n",
    "#### B - MACHINE LEARNING (SkLearn)\n",
    "1. **Model Selection** - Benchmarking Algorithms with default Hyperparameters\n",
    "2. **Hyperparamter Tuning** - Random Search, Learning Curves\n",
    "\n",
    "#### C - DEEP LEARNING (Keras)\n",
    "1. **Neural Nets** - Keras Sequential Model\n",
    "2. **CNNs** - from Scratch, Transferlearning\n",
    "3. **RNNs** - from Scratch, Transferlearning\n",
    "4. **Complex Model Graphs** - Functional Keras API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook B1 - Model Selection\n",
    "\n",
    "* [**Preprocess Data**](#pd)\n",
    "* [**Classification**](#clf)\n",
    "* [**Regression**](#reg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocess Data<a name=\"pd\"></a>\n",
    "\n",
    "For details refer to previous notebook 1_DataPreprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "titanic = sns.load_dataset('titanic')\n",
    "\n",
    "# Directly remove features 'alive' and 'embark_town' which duplicate 'survived' and 'embark'\n",
    "titanic = titanic.drop(columns=['embark_town', 'alive'])\n",
    "\n",
    "# Drop feature 'deck' with too many NAs\n",
    "titanic = titanic.drop(columns='deck')\n",
    "\n",
    "# Impute age with average\n",
    "titanic.loc[titanic.age.isna(), 'age'] = titanic.age.mean()\n",
    "\n",
    "# Impute embarked with most frequent\n",
    "titanic.embarked.value_counts()\n",
    "\n",
    "# One hot encode categorical features\n",
    "titanic_categorical = titanic.loc[:, (titanic.dtypes=='object') | (titanic.dtypes=='category')]\n",
    "titanic = titanic.drop(columns=titanic_categorical.columns)\n",
    "titanic = titanic.join(pd.get_dummies(titanic_categorical, drop_first=True))\n",
    "\n",
    "# Convert everything to float32\n",
    "titanic = titanic.astype('float32')\n",
    "titanic.head()\n",
    "\n",
    "# Lognormalize 'price'\n",
    "titanic['fare'] = np.log(titanic.fare+1)\n",
    "\n",
    "# Normalize non-categorical features\n",
    "titanic.loc[:, 'pclass':'fare'] = (titanic.loc[:, 'pclass':'fare'] - titanic.loc[:, 'pclass':'fare'].mean()) /\\\n",
    "                                                                     titanic.loc[:, 'pclass':'fare'].std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification<a name=\"clf\"></a>\n",
    "\n",
    "Predict survival (yes/no) from other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Classifier</th>\n",
       "      <th>Train_ms</th>\n",
       "      <th>Predict_ms</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>1.513391</td>\n",
       "      <td>3.483716</td>\n",
       "      <td>0.824627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaiveBayes</td>\n",
       "      <td>1.350017</td>\n",
       "      <td>0.432137</td>\n",
       "      <td>0.809701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogReg</td>\n",
       "      <td>1.754439</td>\n",
       "      <td>0.524399</td>\n",
       "      <td>0.817164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SvmLin</td>\n",
       "      <td>11.144754</td>\n",
       "      <td>2.008616</td>\n",
       "      <td>0.820896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SvmPoly</td>\n",
       "      <td>7.802167</td>\n",
       "      <td>2.111818</td>\n",
       "      <td>0.817164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SvmRBF</td>\n",
       "      <td>9.067215</td>\n",
       "      <td>2.196787</td>\n",
       "      <td>0.828358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.899214</td>\n",
       "      <td>0.376707</td>\n",
       "      <td>0.742537</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>14.178829</td>\n",
       "      <td>1.346006</td>\n",
       "      <td>0.779851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>48.029547</td>\n",
       "      <td>5.297596</td>\n",
       "      <td>0.817164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>59.730792</td>\n",
       "      <td>0.952889</td>\n",
       "      <td>0.828358</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Classifier   Train_ms  Predict_ms  Accuracy\n",
       "0            KNN   1.513391    3.483716  0.824627\n",
       "1     NaiveBayes   1.350017    0.432137  0.809701\n",
       "2         LogReg   1.754439    0.524399  0.817164\n",
       "3         SvmLin  11.144754    2.008616  0.820896\n",
       "4        SvmPoly   7.802167    2.111818  0.817164\n",
       "5         SvmRBF   9.067215    2.196787  0.828358\n",
       "6   DecisionTree   1.899214    0.376707  0.742537\n",
       "7   RandomForest  14.178829    1.346006  0.779851\n",
       "8       AdaBoost  48.029547    5.297596  0.817164\n",
       "9  GradientBoost  59.730792    0.952889  0.828358"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import warnings\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Switch off future warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# train_test_split() deploys shuffle=True per default\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(titanic.drop('survived', axis=1), titanic.survived, test_size=0.3, random_state=42)\n",
    "\n",
    "def assess_classifier(clf_name, clf, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    start_fit = time.clock()\n",
    "    clf.fit(X_train, y_train)\n",
    "    start_pred = time.clock()\n",
    "    y_pred = clf.predict(X_test)\n",
    "    finished = time.clock()\n",
    "    \n",
    "    miliseconds_fitting = 1000*(start_pred - start_fit)\n",
    "    miliseconds_prediction = 1000*(finished - start_pred)\n",
    "    clf_accuracy = accuracy_score(y_test, y_pred)\n",
    "     \n",
    "    return [clf_name, miliseconds_fitting, miliseconds_prediction, clf_accuracy]\n",
    "\n",
    "clf_bench = []\n",
    "for clf_name, clf in [['KNN', KNeighborsClassifier()], \\\n",
    "                      ['NaiveBayes', GaussianNB()], \\\n",
    "                      ['LogReg', LogisticRegression()], \\\n",
    "                      ['SvmLin', SVC(kernel='linear', random_state=42)], \\\n",
    "                      ['SvmPoly', SVC(kernel='poly', random_state=42)], \\\n",
    "                      ['SvmRBF', SVC(kernel='rbf', random_state=42)], \\\n",
    "                      ['DecisionTree', DecisionTreeClassifier(random_state=42)], \\\n",
    "                      ['RandomForest', RandomForestClassifier(random_state=42)], \\\n",
    "                      ['AdaBoost', AdaBoostClassifier(random_state=42)], \\\n",
    "                      ['GradientBoost', GradientBoostingClassifier(random_state=42)]]:\n",
    "    clf_bench.append(assess_classifier(clf_name, clf, X_train, X_test, y_train, y_test))\n",
    "\n",
    "clf_bench = pd.DataFrame(clf_bench)\n",
    "clf_bench.columns = ['Classifier', 'Train_ms', 'Predict_ms', 'Accuracy']\n",
    "clf_bench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression<a name=\"reg\"></a>\n",
    "\n",
    "Predict age from other features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Regressor</th>\n",
       "      <th>Train_ms</th>\n",
       "      <th>Predict_ms</th>\n",
       "      <th>RMSE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>1.304433</td>\n",
       "      <td>3.221152</td>\n",
       "      <td>0.838755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LinReg</td>\n",
       "      <td>0.995920</td>\n",
       "      <td>0.319818</td>\n",
       "      <td>0.805855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SvmLin</td>\n",
       "      <td>31.227265</td>\n",
       "      <td>2.768958</td>\n",
       "      <td>0.822488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SvmPoly</td>\n",
       "      <td>21.852631</td>\n",
       "      <td>3.537687</td>\n",
       "      <td>0.879784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SvmRBF</td>\n",
       "      <td>17.758818</td>\n",
       "      <td>4.795807</td>\n",
       "      <td>0.823424</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>DecisionTree</td>\n",
       "      <td>1.820809</td>\n",
       "      <td>0.346803</td>\n",
       "      <td>0.929230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForest</td>\n",
       "      <td>13.976071</td>\n",
       "      <td>1.199043</td>\n",
       "      <td>0.838855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AdaBoost</td>\n",
       "      <td>14.864413</td>\n",
       "      <td>1.350382</td>\n",
       "      <td>0.849576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>GradientBoost</td>\n",
       "      <td>38.761397</td>\n",
       "      <td>0.907305</td>\n",
       "      <td>0.808432</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Regressor   Train_ms  Predict_ms      RMSE\n",
       "0            KNN   1.304433    3.221152  0.838755\n",
       "1         LinReg   0.995920    0.319818  0.805855\n",
       "2         SvmLin  31.227265    2.768958  0.822488\n",
       "3        SvmPoly  21.852631    3.537687  0.879784\n",
       "4         SvmRBF  17.758818    4.795807  0.823424\n",
       "5   DecisionTree   1.820809    0.346803  0.929230\n",
       "6   RandomForest  13.976071    1.199043  0.838855\n",
       "7       AdaBoost  14.864413    1.350382  0.849576\n",
       "8  GradientBoost  38.761397    0.907305  0.808432"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from math import sqrt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "\n",
    "# train_test_split() deploys shuffle=True per default\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "        train_test_split(titanic.drop('age', axis=1), titanic.age, test_size=0.3, random_state=42)\n",
    "\n",
    "def assess_regressor(reg_name, reg, X_train, X_test, y_train, y_test):\n",
    "    \n",
    "    start_fit = time.clock()\n",
    "    reg.fit(X_train, y_train)\n",
    "    start_pred = time.clock()\n",
    "    y_pred = reg.predict(X_test)\n",
    "    finished = time.clock()\n",
    "    \n",
    "    miliseconds_fitting = 1000*(start_pred - start_fit)\n",
    "    miliseconds_prediction = 1000*(finished - start_pred)\n",
    "    reg_rmse = sqrt(mean_squared_error(y_test, y_pred))\n",
    "     \n",
    "    return [reg_name, miliseconds_fitting, miliseconds_prediction, reg_rmse]\n",
    "\n",
    "reg_bench = []\n",
    "for reg_name, reg in [['KNN', KNeighborsRegressor()], \\\n",
    "                      ['LinReg', LinearRegression()], \\\n",
    "                      ['SvmLin', SVR(kernel='linear')], \\\n",
    "                      ['SvmPoly', SVR(kernel='poly')], \\\n",
    "                      ['SvmRBF', SVR(kernel='rbf')], \\\n",
    "                      ['DecisionTree', DecisionTreeRegressor()], \\\n",
    "                      ['RandomForest', RandomForestRegressor()], \\\n",
    "                      ['AdaBoost', AdaBoostRegressor()], \\\n",
    "                      ['GradientBoost', GradientBoostingRegressor()]]:\n",
    "    reg_bench.append(assess_regressor(reg_name, reg, X_train, X_test, y_train, y_test))\n",
    "\n",
    "reg_bench = pd.DataFrame(reg_bench)\n",
    "reg_bench.columns = ['Regressor', 'Train_ms', 'Predict_ms', 'RMSE']\n",
    "reg_bench"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x209790fd710>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x209790a2470>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compare RMSE with normalized 'age' distri\n",
    "titanic.age.plot.hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
